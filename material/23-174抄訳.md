## 23-174 Asynchronous Tasks in Fortran の抄訳

### 1. はじめに
非同期性 (asynchrony) の原理は、計算における多くの面で基本的なものであり、様々な形で現れる。しかし、Fortranのもつ非同期性は、次のように不十分である。

- 共配列(coarray)は非同期実行(asynchronous execution)をサポートしているが、次の理由により、いくつかのユースケースではあまり適していない。
	1. データを像 (image) の間で明示的に通信する必要がある。
	2. 実行時には像の数が変えられない。

- DO CONCURRENT構文によって非同期実行ができるが、DO CONCURRENT構文内には、純粋(pure)な手続しか許されないなどの多くの制限がある。そのため、長時間実行タスクや複雑なタスクは、DO CONCURRENTの領域内に収まるように変形できない。

### 2. 関連した取組み
高性能計算 (HPC) の領域では、OpenMPとOpenACCの指示行 (directive) が非同期実行をサポートし、Fortranアプリケーションで使用されている。
機能 | 概要
-----|---------------------
Adaのタスク | 言語の第一級機能 (first-class feature)。OSのスレッドに似て、親スコープのデータを参照でき、プログラム内で生成と破棄が可能。
C11のスレッド | ユーザはスレッドを発生させ (spawn)、データへのポインタを与えることができる。Adaとは異なり、アクセス競合を避けるためにはatomic operationやmutexを明示的に使用しなければならない。
C++のスレッド | C++11は、C11のスレッド関連機能に加え、async, promise, futureなどの機能をもつ。後の版では、FortranのDO CONCURRENTのような機能が導入された。
OpenMPのタスク | OpenMP 3.1でタスクが導入されたが、親タスクが子タスクを待ち受ける以外の依存関係をサポートしていない。OpenMP 4.0では、メモリの位置を識別子として使用するタスクの同期が可能になった（訳註: OpenMPには、target指示行など、GPUなどのデバイスを実行させるための機能もある）。
OpenACCのasync | OpenACCのasyncは、GPUのようなデバイスの非同期実行を可能にする、キューのようなメカニズムを提供する。複数の非同期ストリーム (streams of asynchrony) をasyncに与える整数の番号によって指定する。実装として、複数の非同期ストリームを逐次的に実行することも許される。

### 3. 動機付けとなる例
モダンなコンピュータは、一般的に、CPUコアのようなものだけでなく、特別な別のものをもっている。

- Intelの最新のCPU (Sapphire Rapids) は、データ並列計算ができるData Streaming Accelerator (DSA)をもっている。DSAはDO CONCURRENTに使えるが、現在の（Fortranの）semanticsでは、構文をDSAに実行させている間に制御を戻して直ちにCPUに次のコードを実行させるメカニズムはプログラマに提供されていない。
- 最近のNVIDIAのGPUは、プロセッサ内の非同期コピーエンジンや、GPU外とのコピーのための非同期DMA (direct memory access) 機構をもっている。
- DSAと同様な計算エンジンは他にも存在する。例えば、AppleとIntelとNVIDIAのプロセッサは、FortranのMATMULが使う機能について専用のマトリックス計算ユニットをもつ。それは汎用ロジックの部分とは別のシリコンでできていて、独立に非同期で実行することができる。

共配列は、（データの共有ができないため）像間で無駄なコピーが生じる。DO CONCURRENTは高度に構造化されたデータ並列に限られるので、OSのスレッドなど、非同期タスクで表現されるマルチコア並列には適さない。コアを跨いだ並列実行にコンパイラが自動変換することは、採算性を証明することは難しくリスクもあるため、ほとんど行われない。

アクセラレータやコプロセッサは、高帯域幅のインターコネクトを介してCPUに接続されていて、Fortran言語を大部分サポートする。最近では、NVIDIAとIntelの両社がDO CONCURRENTをGPU上でサポートし始めた。しかし、プログラマは、OpenCL、CUDA、HIP、SYCL（またはIntelのData Parallel C++）のようなAPIではデフォルトで記述できるようなGPU計算の非同期性を、現在のsemanticsでは記述できない。OpenMPまたはOpenACCを使うFortranプログラムならDO CONCURRENT中で非同期の動作を実現できるが、標準から外れてしまう。

### 4. 非同期通信
ライブラリベースの通信（MPI、OpenSHMEMなど）にはnon-blocking操作がある。共配列の操作は像間で非同期だが、集団処理操作 (collective operation) は同期なので、集団処理のパイプラインや、集団処理と計算の重ね合わせを表現するメカニズムはない。

量子化学的多体論 (Quantum chemical many-body theory) は、オーバーラップが有効な具体例である。数十から数百の項を計算するが、その多くは互いに独立している。DO CURRENTやMATMULなどが他の部分に対して独立に非同期で実行できるFortran実装では、同期GPU実装に比べて2.5倍のスピードアップがあった。

### 5. Fortranで非同期性を活かす機会

#### 5.1 コプロセッサ (coprocessor) によるDO CONCURRENTの実行
例えば、DO CONCURRENT構文の後に手続呼出しがあって、それらに依存関係がないとき、DO CONCURRENT構文をGPUに実行させ、その間にCPUで手続呼出しを実行する。

#### 5.2 データ並列組込み手続（例えば、MATMUL）
NVIDIA Fortranは、GPU上でMATMUL、TRANSPOSE、配列代入などの多数のデータ並列演算の実行をサポートする。CUDAでのこれらのルーチンの基本的なライブラリ実装は自然に非同期になっているが、Fortranコンパイラには、それをユーザに公開するための標準的な構文がない。現状では、プログラマがストリームを非同期で実行させるためには、OpenACCディレクティブに頼るしかない。これはDO CONCURRENTを使っても解決しない。

#### 5.3 共配列の集団処理 (collective) 通信
次の例で、変数A,B,C,Dが互いに無依存であるとき、三つの共配列の集団処理は互いに同期する必要はないし、次のPRINT文の実行が始まる前に完了する必要はない。
```
    co_sum(A)
    co_min(B)
    co_max(C)
    print *, D
```
MPI-3では、この非依存の性質はnonblocking collectivesを使って自然に表現できる。

#### 5.4 その他の非同期演算
独立に実行可能なコードは、理論的にはコンパイラが自動認識できるが、その実装はあまり成功していない。競合するデータ参照がないことや、実行時オーバーヘッドを上回る利得があることの証明が難しいからである。基本的に、並列性と非同期性の実装で成功したものはすべて明示的である。

多くの明示的な非同期性の書式では、プログラマは、プログラム内にスレッドを生成し、それに実行手続を関連付ける。データ参照の競合には、atomic operationなどの同期primitiveを使って明示的に対処する。

- Adaでは、ランデブーなどのタスク間同期があり得るので、デッドロックを避けるため、タスクを並列実行エージェントにマッピングするか、または、コルーチンを使うなどしてタスクを並列にスケジュールしなければならない。

- OpenMPでは、Adaのような実行時エージェントを持たないので、デッドロックの可能性を排除したタスク間同期はできない。同様に、OpenACCの async も同様である。

- Ada, C 及び C++ ではタスクの同期とスレッドの同期が許されるが、OpenMPのタスクとOpenACCの async は同期が許されない（訳註: OpenMP 3.1から導入された task depend 構文を使えば、タスク間のデータの依存関係を指定できる）。

### 6. Fortranの非同期構文と意味論（提案内容）
1. Adaに倣い、親のタスクに対して非同期である領域を記述するためにTASKという構文を使う。しかし、複雑な実装を避けるため、OpenMPタスクと同じように、Fortranタスクはタスク間の同期を禁止とする。TASK構文はプログラマからのヒントであり、次のことを意味する。

- そこに含まれるコードは、非同期のメカニズム（CPUから独立して動作するOSスレッドまたは専用の実行ユニット）を使って実装してよい。それが望ましく、また、それが有益である。

2. TASK構文はBLOCK構文の拡張とする。DO CONCURRENTをDOとして実装してよい（仕様準拠と言える）のと同じように、TASKをBLOCKとして実装してよい。

3. タスク（暗黙のタスクを含む）は互いに独立して実行される可能性があるので、プログラマはデータ参照の競合を起こしてはならない。同時読み出しは競合しないので常に許される。他の読み出しや書き込みと同時の書き込みは、未定義であり、実装依存の振舞いとなる。DO CONCURRENT は純粋でない手続を明示的に禁止しているが、Fortranタスクはどのような手続を呼び出してもよい。共配列 (coarray) プログラムがそうであるように、データアクセスの競合を避ける責任はプログラマにある。

4. タスクは親タスクから独立に実行されるが、同じ親から生成されたタスクの並びは、その順番に実行される。この振舞いを緩和するために、個々のタスクを異なる実行streamに関連付けることができるとする。タスクの実行streamには整数のラベルを付ける。

5. タスクのstreamは、次のTASK WAIT文で親タスクと同期する。
```
TASK  WAIT [ ( stream-number [ , stream-number ] ... ) ]
stream-number は整定数式
```
stream-number がないとき、TASK WAIT文は全てのstreamと同期する。このstreamの構文と意味論はOpenACCのasyncに似ているので、複数のコンパイラで実装可能であることが知られている。これは、NOWAITが指定されているか依存関係のないタスクをもつOpenMPの構文に似ている。
Adaのタスクは、問題のあるプログラムを除外するために、多くの重要な意味論を提供する。例えば、親タスクは、子タスクが未解決のデータ参照を持っている間は終了してはならない。これは、プログラムのデバッグが不正確で困難になりがちだからである。同様に、Fortanでは、子タスクが親タスクに関連するデータを参照していない場合を除いて、親タスクは子タスクを暗黙的に待つとする。

6. Fortranタスクには、データの access property を記述する方法が必要になる。LOCALITY指定子が利用できるが、これはOpenMPとOpenACCが非同期やタスク領域の振舞いを記述するために使用するものと似ている。FortranのTASK構文内は、次のようにLOCALITY文で始まる。

```
TASK [ ( stream-number [ , stream-number ] ... ) ]
    LOCALITY(SHARED) :: X(:)      ! 共有される。ただし競合 (conflict) する参照は禁止。
    LOCALITY(LOCAL_INIT) :: IBEGIN, IEND, IX
    REAL :: A
    A = COS(IX)
    X(IBEGIN:IEND) = A 
END TASK
``` 

上記のタスクで代入される配列Xの範囲は、親タスクから与えられている。

タスクでは、LOCALITY指定子として "REDUCE" は許されないとする。

タスク内で宣言されたデータは、その親タスクからは参照できないが、その子タスクからは子タスクのLOCALITY文に従ってアクセスすることができる。


